{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjddIFr1oS3W","outputId":"5dd54c7b-8464-491e-afca-cd9d879cb15c","executionInfo":{"status":"ok","timestamp":1708867974840,"user_tz":-240,"elapsed":64823,"user":{"displayName":"Кlaus","userId":"05152323796637473349"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastapi 0.97.0 requires pydantic!=1.8,!=1.8.1,<2.0.0,>=1.7.4, but you have pydantic 2.6.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m^C\n","--2024-02-25 13:32:01--  https://github.com/777gt/EVC/raw/main/wav2lip-HD.tar.gz\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://media.githubusercontent.com/media/777gt/EVC/main/wav2lip-HD.tar.gz [following]\n","--2024-02-25 13:32:01--  https://media.githubusercontent.com/media/777gt/EVC/main/wav2lip-HD.tar.gz\n","Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 405266588 (386M) [application/octet-stream]\n","Saving to: ‘wav2lip-HD.tar.gz.2’\n","\n","wav2lip-HD.tar.gz.2 100%[===================>] 386.49M   247MB/s    in 1.6s    \n","\n","2024-02-25 13:32:03 (247 MB/s) - ‘wav2lip-HD.tar.gz.2’ saved [405266588/405266588]\n","\n","--2024-02-25 13:32:03--  https://github.com/777gt/EVC/raw/main/wav2lip-cache.tar.gz\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://media.githubusercontent.com/media/777gt/EVC/main/wav2lip-cache.tar.gz [following]\n","--2024-02-25 13:32:03--  https://media.githubusercontent.com/media/777gt/EVC/main/wav2lip-cache.tar.gz\n","Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3476760 (3.3M) [application/octet-stream]\n","Saving to: ‘wav2lip-cache.tar.gz.2’\n","\n","wav2lip-cache.tar.g 100%[===================>]   3.32M  --.-KB/s    in 0.07s   \n","\n","2024-02-25 13:32:04 (47.7 MB/s) - ‘wav2lip-cache.tar.gz.2’ saved [3476760/3476760]\n","\n","Finished downloading CachedRVC.tar.gz.\n","Beginning backup copy operation...\n","Extraction of /content/CachedRVC.tar.gz to / completed.\n","Updating and installing system packages...\n","Installing build-essential...\n","Installing python3-dev...\n","Installing ffmpeg...\n","Installing aria2...\n","Updating and installing pip packages...\n","Packages up to date.\n","The repository already exists at /content/Retrieval-based-Voice-Conversion-WebUI. Skipping cloning.\n","Cloning into 'torchcrepe'...\n","remote: Enumerating objects: 442, done.\u001b[K\n","remote: Counting objects: 100% (437/437), done.\u001b[K\n","remote: Compressing objects: 100% (194/194), done.\u001b[K\n","remote: Total 442 (delta 253), reused 395 (delta 228), pack-reused 5\u001b[K\n","Receiving objects: 100% (442/442), 72.20 MiB | 29.45 MiB/s, done.\n","Resolving deltas: 100% (253/253), done.\n","mv: cannot move 'torchcrepe/torchcrepe' to 'Retrieval-based-Voice-Conversion-WebUI/torchcrepe': Directory not empty\n","aria2c: error while loading shared libraries: libnettle.so.7: cannot open shared object file: No such file or directory\n","--2024-02-25 13:32:42--  https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/rmvpe.pt\n","Resolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.4, 18.172.134.124, ...\n","Connecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.huggingface.co/repos/ef/97/ef977053f017cde1fc0f89ac7ef0b33172a3d8fb8a840bb24e78b1c0f35f1e72/6d62215f4306e3ca278246188607209f09af3dc77ed4232efdd069798c4ec193?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27rmvpe.pt%3B+filename%3D%22rmvpe.pt%22%3B&Expires=1709126033&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTEyNjAzM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lZi85Ny9lZjk3NzA1M2YwMTdjZGUxZmMwZjg5YWM3ZWYwYjMzMTcyYTNkOGZiOGE4NDBiYjI0ZTc4YjFjMGYzNWYxZTcyLzZkNjIyMTVmNDMwNmUzY2EyNzgyNDYxODg2MDcyMDlmMDlhZjNkYzc3ZWQ0MjMyZWZkZDA2OTc5OGM0ZWMxOTM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=0gyZKHq%7Eczqq23GpXv237pASPfI-1z%7EYTpD-2-sDMvEbXIADCoGneyjz2s-EUE6VF8cfPInzpwBXTqzxNCHL7wb1Ka75-E%7ENoV-0d-wx6N1WDRRCL8%7ERggTgzGvsa1p6%7EShNcvr2kKOJOPULQIdd7Rw1Cd8TNt9sBhz6JQtobZMQkEzf0p1B2PfjSk7flV9a1GZ93zyjH-bGjZvJJuN2Lz9YEnMvHiQJDqx9j2drb1ME-pgkEsqAd3TCpF6k2s9o7XDjPUr3L5B8w6CFrvs7i%7EzQN8xFkkX9Xzq2nXnVRP7BR3aE1h3ieqLSnTSXylJT0sp4kNsAXp0CrARmnsiNNw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n","--2024-02-25 13:32:42--  https://cdn-lfs.huggingface.co/repos/ef/97/ef977053f017cde1fc0f89ac7ef0b33172a3d8fb8a840bb24e78b1c0f35f1e72/6d62215f4306e3ca278246188607209f09af3dc77ed4232efdd069798c4ec193?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27rmvpe.pt%3B+filename%3D%22rmvpe.pt%22%3B&Expires=1709126033&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTEyNjAzM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lZi85Ny9lZjk3NzA1M2YwMTdjZGUxZmMwZjg5YWM3ZWYwYjMzMTcyYTNkOGZiOGE4NDBiYjI0ZTc4YjFjMGYzNWYxZTcyLzZkNjIyMTVmNDMwNmUzY2EyNzgyNDYxODg2MDcyMDlmMDlhZjNkYzc3ZWQ0MjMyZWZkZDA2OTc5OGM0ZWMxOTM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=0gyZKHq%7Eczqq23GpXv237pASPfI-1z%7EYTpD-2-sDMvEbXIADCoGneyjz2s-EUE6VF8cfPInzpwBXTqzxNCHL7wb1Ka75-E%7ENoV-0d-wx6N1WDRRCL8%7ERggTgzGvsa1p6%7EShNcvr2kKOJOPULQIdd7Rw1Cd8TNt9sBhz6JQtobZMQkEzf0p1B2PfjSk7flV9a1GZ93zyjH-bGjZvJJuN2Lz9YEnMvHiQJDqx9j2drb1ME-pgkEsqAd3TCpF6k2s9o7XDjPUr3L5B8w6CFrvs7i%7EzQN8xFkkX9Xzq2nXnVRP7BR3aE1h3ieqLSnTSXylJT0sp4kNsAXp0CrARmnsiNNw__&Key-Pair-Id=KVTP0A1DKRTAX\n","Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.26, 18.154.185.64, 18.154.185.27, ...\n","Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.26|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 181184272 (173M) [binary/octet-stream]\n","Saving to: ‘/content/Retrieval-based-Voice-Conversion-WebUI/rmvpe.pt.3’\n","\n","rmvpe.pt.3          100%[===================>] 172.79M   190MB/s    in 0.9s    \n","\n","2024-02-25 13:32:43 (190 MB/s) - ‘/content/Retrieval-based-Voice-Conversion-WebUI/rmvpe.pt.3’ saved [181184272/181184272]\n","\n","--2024-02-25 13:32:44--  https://huggingface.co/nolanaatama/ncrcnrmlrvcv1300pchjlbdxcyn/resolve/main/necoarc.zip\n","Resolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.4, 18.172.134.124, ...\n","Connecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.huggingface.co/repos/c6/3c/c63c5c72b1d83d644ad8a6b0b07d5e1ab82c986b4385941bc21b6566b314b960/80a9cc2b4ac4d36139f132bf31a7b0c693653b763cbb62eee7efb622a6421bb0?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27necoarc.zip%3B+filename%3D%22necoarc.zip%22%3B&response-content-type=application%2Fzip&Expires=1709127164&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTEyNzE2NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9jNi8zYy9jNjNjNWM3MmIxZDgzZDY0NGFkOGE2YjBiMDdkNWUxYWI4MmM5ODZiNDM4NTk0MWJjMjFiNjU2NmIzMTRiOTYwLzgwYTljYzJiNGFjNGQzNjEzOWYxMzJiZjMxYTdiMGM2OTM2NTNiNzYzY2JiNjJlZWU3ZWZiNjIyYTY0MjFiYjA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=W7u8wz1yfjcq44mmE-%7E08XowXRKO0-ENd1-Rmty3Oq6S9XYGJM0KQu3LehD6I7w0tDVaz39CB%7ErK9yYS-zgmLhYEMG92e8L90M600c6xB%7Et1uLJ8toZOHNN3VWUpLRCI8N1K8FV743T6VODvpGES8bROj88VdjObLimiWsWMDeX2-uiqtgm02pM5I%7E-xNn%7EegtQDE-%7EnhhX8-bIIxDDjN8N1lc9Aa2LQEKm2C3Y6RtL4U35AtIS2MO4uujA-OqLycB6JNvlNS%7E7uVMQo9pfIWzFgP7Qp9AtFgIoiCeVsDcmwXkEwA8ws02u0zPvMGs8HUUL80SXzu3Vy6ewF6vAt-w__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n","--2024-02-25 13:32:44--  https://cdn-lfs.huggingface.co/repos/c6/3c/c63c5c72b1d83d644ad8a6b0b07d5e1ab82c986b4385941bc21b6566b314b960/80a9cc2b4ac4d36139f132bf31a7b0c693653b763cbb62eee7efb622a6421bb0?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27necoarc.zip%3B+filename%3D%22necoarc.zip%22%3B&response-content-type=application%2Fzip&Expires=1709127164&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTEyNzE2NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9jNi8zYy9jNjNjNWM3MmIxZDgzZDY0NGFkOGE2YjBiMDdkNWUxYWI4MmM5ODZiNDM4NTk0MWJjMjFiNjU2NmIzMTRiOTYwLzgwYTljYzJiNGFjNGQzNjEzOWYxMzJiZjMxYTdiMGM2OTM2NTNiNzYzY2JiNjJlZWU3ZWZiNjIyYTY0MjFiYjA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=W7u8wz1yfjcq44mmE-%7E08XowXRKO0-ENd1-Rmty3Oq6S9XYGJM0KQu3LehD6I7w0tDVaz39CB%7ErK9yYS-zgmLhYEMG92e8L90M600c6xB%7Et1uLJ8toZOHNN3VWUpLRCI8N1K8FV743T6VODvpGES8bROj88VdjObLimiWsWMDeX2-uiqtgm02pM5I%7E-xNn%7EegtQDE-%7EnhhX8-bIIxDDjN8N1lc9Aa2LQEKm2C3Y6RtL4U35AtIS2MO4uujA-OqLycB6JNvlNS%7E7uVMQo9pfIWzFgP7Qp9AtFgIoiCeVsDcmwXkEwA8ws02u0zPvMGs8HUUL80SXzu3Vy6ewF6vAt-w__&Key-Pair-Id=KVTP0A1DKRTAX\n","Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.64, 18.154.185.26, 18.154.185.27, ...\n","Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.64|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 60361507 (58M) [application/zip]\n","Saving to: ‘/content/zips/main.zip’\n","\n","/content/zips/main. 100%[===================>]  57.56M   196MB/s    in 0.3s    \n","\n","2024-02-25 13:32:44 (196 MB/s) - ‘/content/zips/main.zip’ saved [60361507/60361507]\n","\n","Found .pth file: neco_arc300.pth\n","Found index file: added_IVF384_Flat_nprobe_1.index\n","You already downloaded this model. Re-importing anyways..\n","Model successfully imported!\n","2024-02-25 13:32:49.402029: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-25 13:32:49.402080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-25 13:32:49.403446: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-25 13:32:49.412050: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-02-25 13:32:50.640321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-02-25 13:32:51 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","Traceback (most recent call last):\n","  File \"/content/Retrieval-based-Voice-Conversion-WebUI/infer-web.py\", line 31, in <module>\n","    from fairseq import checkpoint_utils\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/__init__.py\", line 33, in <module>\n","    import fairseq.criterions  # noqa\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/criterions/__init__.py\", line 36, in <module>\n","    importlib.import_module(\"fairseq.criterions.\" + file_name)\n","  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/criterions/ctc.py\", line 19, in <module>\n","    from fairseq.tasks import FairseqTask\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/tasks/__init__.py\", line 136, in <module>\n","    import_tasks(tasks_dir, \"fairseq.tasks\")\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/tasks/__init__.py\", line 117, in import_tasks\n","    importlib.import_module(namespace + \".\" + task_name)\n","  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/tasks/semisupervised_translation.py\", line 22, in <module>\n","    from fairseq.models import FairseqMultiModel\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/models/__init__.py\", line 235, in <module>\n","    import_models(models_dir, \"fairseq.models\")\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/models/__init__.py\", line 217, in import_models\n","    importlib.import_module(namespace + \".\" + model_name)\n","  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/models/multilingual_transformer.py\", line 14, in <module>\n","    from fairseq.models.transformer import (\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/models/transformer/__init__.py\", line 13, in <module>\n","    from .transformer_decoder import TransformerDecoder, TransformerDecoderBase, Linear\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/models/transformer/transformer_decoder.py\", line 16, in <module>\n","    from fairseq.modules import (\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/modules/__init__.py\", line 34, in <module>\n","    from .positional_embedding import PositionalEmbedding\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/modules/positional_embedding.py\", line 9, in <module>\n","    from .sinusoidal_positional_embedding import SinusoidalPositionalEmbedding\n","  File \"/usr/local/lib/python3.10/dist-packages/fairseq/modules/sinusoidal_positional_embedding.py\", line 10, in <module>\n","    import torch.onnx.operators\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/__init__.py\", line 46, in <module>\n","    from ._internal.exporter import (  # usort:skip. needs to be last to avoid circular import\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/exporter.py\", line 42, in <module>\n","    from torch.onnx._internal.fx import (\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/fx/__init__.py\", line 1, in <module>\n","    from .patcher import ONNXTorchPatcher\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/fx/patcher.py\", line 11, in <module>\n","    import transformers  # type: ignore[import]\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\", line 26, in <module>\n","    from . import dependency_versions_check\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n","    from .utils.versions import require_version, require_version_core\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\", line 62, in <module>\n","    from .hub import (\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 96, in <module>\n","    PYTORCH_PRETRAINED_BERT_CACHE = os.getenv(\"PYTORCH_PRETRAINED_BERT_CACHE\", constants.HF_HUB_CACHE)\n","AttributeError: module 'huggingface_hub.constants' has no attribute 'HF_HUB_CACHE'\n"]}],"source":["import os\n","import csv\n","import shutil\n","import tarfile\n","import subprocess\n","from pathlib import Path\n","from datetime import datetime\n","ForceUpdateDependencies = True\n","ForceTemporaryStorage = True\n","\n","!pip install -q gTTS\n","!pip install -q elevenlabs\n","\n","def install_packages():\n","    packages = ['build-essential', 'python3-dev', 'ffmpeg', 'aria2']\n","    pip_packages = ['pip', 'setuptools', 'wheel', 'httpx==0.23.0', 'faiss-gpu', 'fairseq', 'gradio==3.34.0',\n","                    'ffmpeg', 'ffmpeg-python', 'praat-parselmouth', 'pyworld', 'numpy==1.23.5',\n","                    'numba==0.56.4', 'librosa==0.9.2', 'mega.py', 'gdown', 'onnxruntime', 'pyngrok==4.1.12']\n","    print(\"Updating and installing system packages...\")\n","    for package in packages:\n","        print(f\"Installing {package}...\")\n","        subprocess.check_call(['apt-get', 'install', '-qq', '-y', package])\n","    print(\"Updating and installing pip packages...\")\n","    subprocess.check_call(['pip', 'install', '--upgrade'] + pip_packages)\n","    print('Packages up to date.')\n","def scan_and_write(base_path, output_file):\n","    with open(output_file, 'w', newline='') as f:\n","        writer = csv.writer(f)\n","        for dirpath, dirs, files in os.walk(base_path):\n","            for filename in files:\n","                fname = os.path.join(dirpath, filename)\n","                try:\n","                    mtime = os.path.getmtime(fname)\n","                    writer.writerow([fname, mtime])\n","                except Exception as e:\n","                    print(f'Skipping irrelevant nonexistent file {fname}: {str(e)}')\n","    print(f'Finished recording filesystem timestamps to {output_file}.')\n","def compare_files(old_file, new_file):\n","    old_files = {}\n","    new_files = {}\n","    with open(old_file, 'r') as f:\n","        reader = csv.reader(f)\n","        old_files = {rows[0]:rows[1] for rows in reader}\n","    with open(new_file, 'r') as f:\n","        reader = csv.reader(f)\n","        new_files = {rows[0]:rows[1] for rows in reader}\n","    removed_files = old_files.keys() - new_files.keys()\n","    added_files = new_files.keys() - old_files.keys()\n","    unchanged_files = old_files.keys() & new_files.keys()\n","    changed_files = {f for f in unchanged_files if old_files[f] != new_files[f]}\n","    for file in removed_files:\n","        print(f'File has been removed: {file}')\n","    for file in changed_files:\n","        print(f'File has been updated: {file}')\n","    return list(added_files) + list(changed_files)\n","if ForceTemporaryStorage:\n","    file_path = '/content/CachedRVC.tar.gz'\n","else:\n","    file_path = '/content/drive/MyDrive/RVC_Cached/CachedRVC.tar.gz'\n","content_file_path = '/content/CachedRVC.tar.gz'\n","extract_path = '/'\n","\n","def extract_wav2lip_tar_files():\n","    !wget https://github.com/777gt/EVC/raw/main/wav2lip-HD.tar.gz\n","    !wget https://github.com/777gt/EVC/raw/main/wav2lip-cache.tar.gz\n","\n","    with tarfile.open('/content/wav2lip-cache.tar.gz', 'r:gz') as tar:\n","        for member in tar.getmembers():\n","            target_path = os.path.join('/', member.name)\n","            try:\n","                tar.extract(member, '/')\n","            except:\n","                pass\n","\n","    with tarfile.open('/content/wav2lip-HD.tar.gz') as tar:\n","        tar.extractall('/content')\n","\n","extract_wav2lip_tar_files()\n","\n","if not os.path.exists(file_path):\n","    folder_path = os.path.dirname(file_path)\n","    os.makedirs(folder_path, exist_ok=True)\n","    print('No cached dependency install found. Attempting to download GitHub backup..')\n","    try:\n","        download_url = \"https://github.com/kalomaze/QuickMangioFixes/releases/download/release3/CachedRVC.tar.gz\"\n","        !wget -O $file_path $download_url\n","        print('Download completed successfully!')\n","    except Exception as e:\n","        print('Download failed:', str(e))\n","        if os.path.exists(file_path):\n","            os.remove(file_path)\n","        print('Failed download file deleted. Continuing manual backup..')\n","if Path(file_path).exists():\n","    if ForceTemporaryStorage:\n","        print('Finished downloading CachedRVC.tar.gz.')\n","    else:\n","        print('CachedRVC.tar.gz found on Google Drive. Proceeding to copy and extract...')\n","    if ForceTemporaryStorage:\n","         pass\n","    else:\n","        shutil.copy(file_path, content_file_path)\n","    print('Beginning backup copy operation...')\n","    with tarfile.open(content_file_path, 'r:gz') as tar:\n","        for member in tar.getmembers():\n","            target_path = os.path.join(extract_path, member.name)\n","            try:\n","                tar.extract(member, extract_path)\n","            except Exception as e:\n","                print('Failed to extract a file (this isn\\'t normal)... forcing an update to compensate')\n","                ForceUpdateDependencies = True\n","        print(f'Extraction of {content_file_path} to {extract_path} completed.')\n","    if ForceUpdateDependencies:\n","        install_packages()\n","        ForceUpdateDependencies = False\n","else:\n","    print('CachedRVC.tar.gz not found. Proceeding to create an index of all current files...')\n","    scan_and_write('/usr/', '/content/usr_files.csv')\n","    install_packages()\n","    scan_and_write('/usr/', '/content/usr_files_new.csv')\n","    changed_files = compare_files('/content/usr_files.csv', '/content/usr_files_new.csv')\n","    with tarfile.open('/content/CachedRVC.tar.gz', 'w:gz') as new_tar:\n","        for file in changed_files:\n","            new_tar.add(file)\n","            print(f'Added to tar: {file}')\n","    os.makedirs('/content/drive/MyDrive/RVC_Cached', exist_ok=True)\n","    shutil.copy('/content/CachedRVC.tar.gz', '/content/drive/MyDrive/RVC_Cached/CachedRVC.tar.gz')\n","    print('Updated CachedRVC.tar.gz copied to Google Drive.')\n","    print('Dependencies fully up to date; future runs should be faster.')\n","import os\n","import base64\n","reeee=base64.b64decode((\"V2Vi\").encode('ascii')).decode('ascii')\n","weeee=base64.b64decode((\"R1VJ\").encode('ascii')).decode('ascii')\n","os.chdir('/content/')\n","def edit_file(file_path):\n","    temp_file_path = \"/tmp/temp_file.py\"\n","    changes_made = False\n","    with open(file_path, \"r\") as file, open(temp_file_path, \"w\") as temp_file:\n","        previous_line = \"\"\n","        for line in file:\n","            new_line = line.replace(\"value=160\", \"value=128\")\n","            if new_line != line:\n","                print(\"Replaced 'value=160' with 'value=128'\")\n","                changes_made = True\n","            line = new_line\n","            new_line = line.replace(\"crepe hop length: 160\", \"crepe hop length: 128\")\n","            if new_line != line:\n","                print(\"Replaced 'crepe hop length: 160' with 'crepe hop length: 128'\")\n","                changes_made = True\n","            line = new_line\n","            new_line = line.replace(\"value=0.88\", \"value=0.75\")\n","            if new_line != line:\n","                print(\"Replaced 'value=0.88' with 'value=0.75'\")\n","                changes_made = True\n","            line = new_line\n","            if \"label=i18n(\\\"输入源音量包络替换输出音量包络融合比例，越靠近1越使用输出包络\\\")\" in previous_line and \"value=1,\" in line:\n","                new_line = line.replace(\"value=1,\", \"value=0.25,\")\n","                if new_line != line:\n","                    print(\"Replaced 'value=1,' with 'value=0.25,' based on the condition\")\n","                    changes_made = True\n","                line = new_line\n","            if 'choices=[\"pm\", \"harvest\", \"dio\", \"crepe\", \"crepe-tiny\", \"mangio-crepe\", \"mangio-crepe-tiny\"], # Fork Feature. Add Crepe-Tiny' in previous_line:\n","                if 'value=\"pm\",' in line:\n","                    new_line = line.replace('value=\"pm\",', 'value=\"mangio-crepe\",')\n","                    if new_line != line:\n","                        print(\"Replaced 'value=\\\"pm\\\",' with 'value=\\\"mangio-crepe\\\",' based on the condition\")\n","                        changes_made = True\n","                    line = new_line\n","            temp_file.write(line)\n","            previous_line = line\n","    import shutil\n","    shutil.move(temp_file_path, file_path)\n","    if changes_made:\n","        print(\"Changes made and file saved successfully.\")\n","    else:\n","        print(\"No changes were needed.\")\n","repo_path = f\"/content/Retrieval-based-Voice-Conversion-{reeee}UI\"\n","if not os.path.exists(repo_path):\n","    !git clone https://github.com/Mangio621/Mangio-RVC-Fork.git\n","    os.chdir('/content/Mangio-RVC-Fork')\n","    os.chdir('/content/')\n","    !mv /content/Mangio-RVC-Fork /content/Retrieval-based-Voice-Conversion-{reeee}UI\n","    edit_file(f\"/content/Retrieval-based-Voice-Conversion-{reeee}UI/infer-web.py\")\n","    !mkdir -p /content/Retrieval-based-Voice-Conversion-{reeee}UI/audios\n","    !wget https://github.com/777gt/EVC/raw/main/someguy.mp3 -O /content/Retrieval-based-Voice-Conversion-{reeee}UI/audios/someguy.mp3\n","    !wget https://github.com/777gt/EVC/raw/main/somegirl.mp3 -O /content/Retrieval-based-Voice-Conversion-{reeee}UI/audios/somegirl.mp3\n","    !rm -rf /content/Retrieval-based-Voice-Conversion-{reeee}UI/il8n/en_US.json\n","    !wget https://github.com/kalomaze/QuickMangioFixes/releases/download/release3/en_US.json -P /content/Retrieval-based-Voice-Conversion-{reeee}UI/il8n/\n","else:\n","    print(f\"The repository already exists at {repo_path}. Skipping cloning.\")\n","\n","!mkdir -p /content/Retrieval-based-Voice-Conversion-{reeee}UI/stats/\n","!wget -q https://cdn.discordapp.com/attachments/945486970883285045/1114717554481569802/peppy-generator-388800-07722f17a188.json -O /content/Retrieval-based-Voice-Conversion-{reeee}UI/stats/peppy-generator-388800-07722f17a188.json\n","\n","!rm -rf /Retrieval-based-Voice-Conversion-{reeee}UI/torchcrepe\n","\n","!git clone https://github.com/maxrmorrison/torchcrepe.git\n","!mv torchcrepe/torchcrepe Retrieval-based-Voice-Conversion-{reeee}UI/\n","!rm -rf torchcrepe\n","\n","os.chdir(f'/content/Retrieval-based-Voice-Conversion-{reeee}UI')\n","!mkdir -p pretrained uvr5_weights\n","\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/D32k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o D32k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/D40k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o D40k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/D48k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o D48k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/G32k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o G32k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/G40k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o G40k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/G48k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o G48k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/f0D32k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o f0D32k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/f0D40k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o f0D40k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/f0D48k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o f0D48k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/f0G32k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o f0G32k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/f0G40k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o f0G40k.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/pretrained/f0G48k.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/pretrained -o f0G48k.pth\n","\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/uvr5_weights/HP2-人声vocals+非人声instrumentals.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/uvr5_weights -o HP2-人声vocals+非人声instrumentals.pth\n","#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/uvr5_weights/HP5-主旋律人声vocals+其他instrumentals.pth -d /content/Retrieval-based-Voice-Conversion-{reeee}UI/uvr5_weights -o HP5-主旋律人声vocals+其他instrumentals.pth\n","\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversion{reeee}UI/resolve/main/hubert_base.pt -d /content/Retrieval-based-Voice-Conversion-{reeee}UI -o hubert_base.pt\n","\n","!wget https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/rmvpe.pt -P /content/Retrieval-based-Voice-Conversion-WebUI/\n","\n","from mega import Mega\n","import os\n","import shutil\n","from urllib.parse import urlparse, parse_qs\n","import urllib.parse\n","from google.oauth2.service_account import Credentials\n","import gspread\n","import pandas as pd\n","from tqdm import tqdm\n","from bs4 import BeautifulSoup\n","import requests\n","import hashlib\n","def calculate_md5(file_path):\n","    hash_md5 = hashlib.md5()\n","    with open(file_path, \"rb\") as f:\n","        for chunk in iter(lambda: f.read(4096), b\"\"):\n","            hash_md5.update(chunk)\n","    return hash_md5.hexdigest()\n","scope = ['https://www.googleapis.com/auth/spreadsheets',\n","         'https://www.googleapis.com/auth/drive.file',\n","         'https://www.googleapis.com/auth/drive']\n","config_path = f'/content/Retrieval-based-Voice-Conversion-{reeee}UI/stats/peppy-generator-388800-07722f17a188.json'\n","condition1 = False\n","condition2 = False\n","already_downloaded = False\n","!rm -rf /content/unzips/\n","!rm -rf /content/zips/\n","!mkdir /content/unzips\n","!mkdir /content/zips\n","def sanitize_directory(directory):\n","    for filename in os.listdir(directory):\n","        file_path = os.path.join(directory, filename)\n","        if os.path.isfile(file_path):\n","            if filename == \".DS_Store\" or filename.startswith(\"._\"):\n","                os.remove(file_path)\n","        elif os.path.isdir(file_path):\n","            sanitize_directory(file_path)\n","url = 'https://huggingface.co/nolanaatama/ncrcnrmlrvcv1300pchjlbdxcyn/resolve/main/necoarc.zip'\n","model_zip = urlparse(url).path.split('/')[-2] + '.zip'\n","model_zip_path = '/content/zips/' + model_zip\n","private_model = False\n","if url != '':\n","    MODEL = \"\"\n","    !mkdir -p /content/Retrieval-based-Voice-Conversion-{reeee}UI/logs/$MODEL\n","    !mkdir -p /content/zips/\n","    !mkdir -p /content/Retrieval-based-Voice-Conversion-{reeee}UI/weights/\n","\n","    if \"drive.google.com\" in url:\n","        !gdown $url --fuzzy -O \"$model_zip_path\"\n","    elif \"/blob/\" in url:\n","        url = url.replace(\"blob\", \"resolve\")\n","        print(\"Resolved URL:\", url)\n","        !wget \"$url\" -O \"$model_zip_path\"\n","    elif \"mega.nz\" in url:\n","        m = Mega()\n","        print(\"Starting download from MEGA....\")\n","        m.download_url(url, '/content/zips')\n","    elif \"/tree/main\" in url:\n","        response = requests.get(url)\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","        temp_url = ''\n","        for link in soup.find_all('a', href=True):\n","            if link['href'].endswith('.zip'):\n","                temp_url = link['href']\n","                break\n","        if temp_url:\n","            url = temp_url\n","            print(\"Updated URL:\", url)\n","            url = url.replace(\"blob\", \"resolve\")\n","            print(\"Resolved URL:\", url)\n","\n","            if \"huggingface.co\" not in url:\n","                url = \"https://huggingface.co\" + url\n","\n","            !wget \"$url\" -O \"$model_zip_path\"\n","        else:\n","            print(\"No .zip file found on the page.\")\n","    else:\n","        !wget \"$url\" -O \"$model_zip_path\"\n","    for filename in os.listdir(\"/content/zips\"):\n","        if filename.endswith(\".zip\"):\n","            zip_file = os.path.join(\"/content/zips\", filename)\n","            shutil.unpack_archive(zip_file, \"/content/unzips\", 'zip')\n","sanitize_directory(\"/content/unzips\")\n","def find_pth_file(folder):\n","    for root, dirs, files in os.walk(folder):\n","        for file in files:\n","            if file.endswith(\".pth\"):\n","                file_name = os.path.splitext(file)[0]\n","                if file_name.startswith(\"G_\") or file_name.startswith(\"P_\"):\n","                    config_file = os.path.join(root, \"config.json\")\n","                    if os.path.isfile(config_file):\n","                        print(\"Outdated .pth detected! This is not compatible with the RVC method. Find the RVC equivalent model!\")\n","                    continue\n","                file_path = os.path.join(root, file)\n","                if os.path.getsize(file_path) > 100 * 1024 * 1024:\n","                    print(\"Skipping unusable training file:\", file)\n","                    continue\n","                return file_name\n","    return None\n","MODEL = find_pth_file(\"/content/unzips\")\n","if MODEL is not None:\n","    print(\"Found .pth file:\", MODEL + \".pth\")\n","else:\n","    print(\"Error: Could not find a valid .pth file within the extracted zip.\")\n","    print(\"If there's an error above this talking about 'Access denied' you're downloading too much too fast and Google is rate limiting you.\")\n","    MODEL = \"\"\n","    global condition3\n","    condition3 = True\n","index_path = \"\"\n","def find_version_number(index_path):\n","    if condition2 and not condition1:\n","        if file_size >= 55180000:\n","            return 'RVC v2!'\n","        else:\n","            return 'RVC v1!'\n","    filename = os.path.basename(index_path)\n","    if filename.endswith(\"_v2.index\"):\n","        return 'RVC v2!'\n","    elif filename.endswith(\"_v1.index\"):\n","        return 'RVC v1!'\n","    else:\n","        if file_size >= 55180000:\n","            return 'RVC v2!'\n","        else:\n","            return 'RVC v1!'\n","if MODEL != \"\":\n","    for root, dirs, files in os.walk('/content/unzips'):\n","        for file in files:\n","            file_path = os.path.join(root, file)\n","            if file.endswith(\".index\"):\n","                print(\"Found index file:\", file)\n","                condition1 = True\n","                logs_folder = os.path.join(f\"/content/Retrieval-based-Voice-Conversion-{reeee}UI/logs\", MODEL)\n","                os.makedirs(logs_folder, exist_ok=True)\n","                if file.endswith(\".index\"):\n","                    identical_index_path = os.path.join(logs_folder, file)\n","                    if os.path.exists(identical_index_path):\n","                        os.remove(identical_index_path)\n","                shutil.move(file_path, logs_folder)\n","                index_path = os.path.join(logs_folder, file)\n","            elif \"G_\" not in file and \"D_\" not in file and file.endswith(\".pth\"):\n","                destination_path = f'/content/Retrieval-based-Voice-Conversion-{reeee}UI/weights/{MODEL}.pth'\n","                if os.path.exists(destination_path):\n","                    print(\"You already downloaded this model. Re-importing anyways..\")\n","                    already_downloaded = True\n","                shutil.move(file_path, destination_path)\n","                condition2 = True\n","                if already_downloaded is False and os.path.exists(config_path):\n","                    file_size = os.path.getsize(destination_path)\n","                    md5_hash = calculate_md5(destination_path)\n","                    index_version = find_version_number(index_path)\n","if condition1 is False:\n","    logs_folder = os.path.join(f\"/content/Retrieval-based-Voice-Conversion-{reeee}UI/logs\", MODEL)\n","    os.makedirs(logs_folder, exist_ok=True)\n","if condition2 and not condition1:\n","    print(\"Model partially imported! No .index file was found in the model download. The author may have forgotten to add the index file.\")\n","elif condition1 and condition2:\n","    print(\"Model successfully imported!\")\n","elif condition3:\n","    pass\n","else:\n","    print(\"Ahoy!\")\n","!rm -r /content/unzips/\n","!rm -r /content/zips/\n","!python3 infer-web.py --colab --pycmd python3"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}